#!/usr/bin/env python3
"""
takawasiå€‹äººé–‹ç™ºåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
dev-analytics-dashboard

Gitæ´»å‹•åˆ†æãƒ»ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æãƒ»ç”Ÿç”£æ€§å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import subprocess
import json
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import re
from pathlib import Path
from collections import Counter, defaultdict
import sys

class DevAnalyticsDashboard:
    def __init__(self, base_dir=None):
        self.base_dir = base_dir or os.path.expanduser("~")
        self.git_repos = []
        self.analysis_data = {}
        self.output_dir = "analytics_output"
        
        # takawasièªéŒ²ãƒªã‚¹ãƒˆï¼ˆã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ†æç”¨ï¼‰
        self.takawasi_keywords = [
            "é›»æ’ƒæˆ¦", "ç¾å ´çŒ«", "ã‚°ãƒ‡ãƒ¼ãƒªã‚¢ãƒ³", "ä¸€æ’ƒ", "å®Œç’§",
            "TSL", "takawasi", "ãƒ¨ã‚·", "ã‚¨ãƒ©ãƒ¼ãªã—", "å“è³ªç®¡ç†",
            "AIå”åƒ", "WSL", "Claude", "åç›ŠåŒ–", "å–¶æ¥­"
        ]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã¨è¨€èªã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.language_mapping = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.ts': 'TypeScript', 
            '.cpp': 'C++',
            '.c': 'C',
            '.java': 'Java',
            '.sh': 'Bash',
            '.md': 'Markdown',
            '.html': 'HTML',
            '.css': 'CSS',
            '.json': 'JSON',
            '.yml': 'YAML',
            '.yaml': 'YAML'
        }
    
    def discover_git_repositories(self):
        """Git ãƒªãƒã‚¸ãƒˆãƒªã®è‡ªå‹•ç™ºè¦‹"""
        print("ğŸ” Git ãƒªãƒã‚¸ãƒˆãƒªã‚’æ¤œç´¢ä¸­...")
        
        git_repos = []
        
        # ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¤œç´¢
        for root, dirs, files in os.walk(self.base_dir):
            # .git ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç™ºè¦‹ã—ãŸå ´åˆ
            if '.git' in dirs:
                repo_path = root
                repo_name = os.path.basename(repo_path)
                
                # .vscode-server ãªã©é™¤å¤–
                if not any(skip in repo_path for skip in ['.vscode', 'node_modules', '__pycache__']):
                    git_repos.append({
                        'name': repo_name,
                        'path': repo_path,
                        'relative_path': os.path.relpath(repo_path, self.base_dir)
                    })
                
                # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® .git ã¯é™¤å¤–
                dirs.remove('.git')
        
        self.git_repos = git_repos
        print(f"âœ… ç™ºè¦‹ã—ãŸãƒªãƒã‚¸ãƒˆãƒª: {len(git_repos)}ä»¶")
        
        for repo in git_repos:
            print(f"  ğŸ“ {repo['name']} ({repo['relative_path']})")
        
        return git_repos
    
    def analyze_git_activity(self, repo_path):
        """Gitæ´»å‹•åˆ†æ"""
        try:
            os.chdir(repo_path)
            
            # Git log å–å¾— (æœ€è¿‘30æ—¥)
            since_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            # ã‚³ãƒŸãƒƒãƒˆæƒ…å ±å–å¾—
            git_log_cmd = [
                'git', 'log', 
                f'--since={since_date}',
                '--pretty=format:%H|%an|%ad|%s|%ai',
                '--date=iso'
            ]
            
            result = subprocess.run(git_log_cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                return None
            
            commits = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    parts = line.split('|')
                    if len(parts) >= 5:
                        commit_hash, author, date, message, iso_date = parts
                        commits.append({
                            'hash': commit_hash,
                            'author': author,
                            'date': date,
                            'message': message,
                            'iso_date': iso_date,
                            'takawasi_keywords': [kw for kw in self.takawasi_keywords if kw in message]
                        })
            
            # ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆå–å¾—
            stats_cmd = ['git', 'log', f'--since={since_date}', '--numstat', '--pretty=format:']
            stats_result = subprocess.run(stats_cmd, capture_output=True, text=True)
            
            file_changes = {'additions': 0, 'deletions': 0, 'files_changed': 0}
            
            if stats_result.returncode == 0:
                for line in stats_result.stdout.strip().split('\n'):
                    if line and '\t' in line:
                        parts = line.split('\t')
                        if len(parts) >= 3:
                            additions = parts[0]
                            deletions = parts[1]
                            
                            if additions.isdigit():
                                file_changes['additions'] += int(additions)
                            if deletions.isdigit():
                                file_changes['deletions'] += int(deletions)
                            file_changes['files_changed'] += 1
            
            return {
                'commits': commits,
                'file_changes': file_changes,
                'total_commits': len(commits),
                'active_days': len(set(c['date'][:10] for c in commits))
            }
            
        except Exception as e:
            print(f"âš ï¸ Gitåˆ†æã‚¨ãƒ©ãƒ¼ ({repo_path}): {e}")
            return None
    
    def analyze_code_quality(self, repo_path):
        """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ"""
        try:
            code_stats = {
                'total_files': 0,
                'total_lines': 0,
                'languages': defaultdict(int),
                'file_sizes': [],
                'python_complexity': {}
            }
            
            for root, dirs, files in os.walk(repo_path):
                # .git, __pycache__ ãªã©ã‚’é™¤å¤–
                dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
                
                for file in files:
                    file_path = os.path.join(root, file)
                    file_ext = os.path.splitext(file)[1].lower()
                    
                    # è¨€èªåˆ¤å®š
                    language = self.language_mapping.get(file_ext, 'Other')
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            lines = f.readlines()
                            line_count = len(lines)
                            
                            code_stats['total_files'] += 1
                            code_stats['total_lines'] += line_count
                            code_stats['languages'][language] += line_count
                            code_stats['file_sizes'].append(line_count)
                            
                            # Python ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ç°¡æ˜“è¤‡é›‘æ€§åˆ†æ
                            if file_ext == '.py':
                                complexity = self.analyze_python_complexity(lines)
                                code_stats['python_complexity'][file] = complexity
                                
                    except Exception:
                        continue
            
            return code_stats
            
        except Exception as e:
            print(f"âš ï¸ ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼ ({repo_path}): {e}")
            return None
    
    def analyze_python_complexity(self, lines):
        """Python ã‚³ãƒ¼ãƒ‰ã®ç°¡æ˜“è¤‡é›‘æ€§åˆ†æ"""
        complexity_indicators = {
            'functions': 0,
            'classes': 0,
            'imports': 0,
            'comments': 0,
            'conditionals': 0,
            'loops': 0
        }
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('def '):
                complexity_indicators['functions'] += 1
            elif line.startswith('class '):
                complexity_indicators['classes'] += 1
            elif line.startswith('import ') or line.startswith('from '):
                complexity_indicators['imports'] += 1
            elif line.startswith('#'):
                complexity_indicators['comments'] += 1
            elif any(keyword in line for keyword in ['if ', 'elif ', 'else:']):
                complexity_indicators['conditionals'] += 1
            elif any(keyword in line for keyword in ['for ', 'while ']):
                complexity_indicators['loops'] += 1
        
        return complexity_indicators
    
    def generate_productivity_insights(self):
        """ç”Ÿç”£æ€§ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = []
        total_commits = sum(data.get('total_commits', 0) for data in self.analysis_data.values())
        total_files = sum(data['code_quality'].get('total_files', 0) 
                         for data in self.analysis_data.values() 
                         if 'code_quality' in data)
        
        # åŸºæœ¬çµ±è¨ˆ
        insights.append(f"ğŸ“Š ç·ã‚³ãƒŸãƒƒãƒˆæ•°: {total_commits}")
        insights.append(f"ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        
        # æœ€ã‚‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªãƒã‚¸ãƒˆãƒª
        if self.analysis_data:
            most_active = max(self.analysis_data.items(), 
                            key=lambda x: x[1].get('total_commits', 0))
            insights.append(f"ğŸ”¥ æœ€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {most_active[0]} ({most_active[1].get('total_commits', 0)} commits)")
        
        # takawasièªéŒ²ä½¿ç”¨é »åº¦
        keyword_usage = Counter()
        for data in self.analysis_data.values():
            if 'git_activity' in data:
                for commit in data['git_activity']['commits']:
                    keyword_usage.update(commit['takawasi_keywords'])
        
        if keyword_usage:
            top_keyword = keyword_usage.most_common(1)[0]
            insights.append(f"âš¡ é »å‡ºtakawasièªéŒ²: '{top_keyword[0]}' ({top_keyword[1]}å›)")
        
        # è¨€èªåˆ¥åˆ†æ
        language_stats = defaultdict(int)
        for data in self.analysis_data.values():
            if 'code_quality' in data:
                for lang, lines in data['code_quality']['languages'].items():
                    language_stats[lang] += lines
        
        if language_stats:
            top_language = max(language_stats.items(), key=lambda x: x[1])
            insights.append(f"ğŸ’» ä¸»è¦è¨€èª: {top_language[0]} ({top_language[1]:,} lines)")
        
        # æ”¹å–„ææ¡ˆ
        insights.append("\nğŸ¯ æ”¹å–„ææ¡ˆ:")
        if total_commits < 10:
            insights.append("  â€¢ ã‚³ãƒŸãƒƒãƒˆé »åº¦ã‚’ä¸Šã’ã¦ç´°ã‹ã„é€²æ—ã‚’è¨˜éŒ²ã—ã¾ã—ã‚‡ã†")
        if keyword_usage.get('å“è³ªç®¡ç†', 0) < keyword_usage.get('é›»æ’ƒæˆ¦', 0):
            insights.append("  â€¢ å“è³ªç®¡ç†ã¸ã®è¨€åŠã‚’å¢—ã‚„ã™ã¨ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ããªã‚Šã¾ã™")
        if language_stats.get('Markdown', 0) < language_stats.get('Python', 0) * 0.1:
            insights.append("  â€¢ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆï¼ˆMarkdownï¼‰ã‚’å¢—ã‚„ã™ã¨è‰¯ã„ã§ã—ã‚‡ã†")
        
        return insights
    
    def create_visualizations(self):
        """å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä½œæˆ"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        plt.style.use('default')
        
        # 1. ãƒªãƒã‚¸ãƒˆãƒªåˆ¥ã‚³ãƒŸãƒƒãƒˆæ•°
        plt.figure(figsize=(12, 6))
        
        repo_names = list(self.analysis_data.keys())
        commit_counts = [data.get('total_commits', 0) for data in self.analysis_data.values()]
        
        plt.subplot(2, 2, 1)
        plt.bar(repo_names, commit_counts, color='skyblue')
        plt.title('ğŸ“Š ãƒªãƒã‚¸ãƒˆãƒªåˆ¥ã‚³ãƒŸãƒƒãƒˆæ•° (30æ—¥é–“)')
        plt.xticks(rotation=45, ha='right')
        plt.ylabel('ã‚³ãƒŸãƒƒãƒˆæ•°')
        
        # 2. è¨€èªåˆ¥ã‚³ãƒ¼ãƒ‰è¡Œæ•°
        language_stats = defaultdict(int)
        for data in self.analysis_data.values():
            if 'code_quality' in data:
                for lang, lines in data['code_quality']['languages'].items():
                    language_stats[lang] += lines
        
        if language_stats:
            plt.subplot(2, 2, 2)
            languages = list(language_stats.keys())[:5]  # ä¸Šä½5è¨€èª
            line_counts = [language_stats[lang] for lang in languages]
            plt.pie(line_counts, labels=languages, autopct='%1.1f%%')
            plt.title('ğŸ’» è¨€èªåˆ¥ã‚³ãƒ¼ãƒ‰è¡Œæ•°')
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†å¸ƒ
        all_file_sizes = []
        for data in self.analysis_data.values():
            if 'code_quality' in data:
                all_file_sizes.extend(data['code_quality']['file_sizes'])
        
        if all_file_sizes:
            plt.subplot(2, 2, 3)
            plt.hist(all_file_sizes, bins=20, color='lightcoral', alpha=0.7)
            plt.title('ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†å¸ƒ')
            plt.xlabel('è¡Œæ•°')
            plt.ylabel('ãƒ•ã‚¡ã‚¤ãƒ«æ•°')
        
        # 4. takawasièªéŒ²ä½¿ç”¨é »åº¦
        keyword_usage = Counter()
        for data in self.analysis_data.values():
            if 'git_activity' in data:
                for commit in data['git_activity']['commits']:
                    keyword_usage.update(commit['takawasi_keywords'])
        
        if keyword_usage:
            plt.subplot(2, 2, 4)
            keywords = list(keyword_usage.keys())[:5]
            counts = [keyword_usage[kw] for kw in keywords]
            plt.bar(keywords, counts, color='lightgreen')
            plt.title('âš¡ takawasièªéŒ²ä½¿ç”¨é »åº¦')
            plt.xticks(rotation=45, ha='right')
            plt.ylabel('ä½¿ç”¨å›æ•°')
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/dev_analytics_dashboard.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä¿å­˜: {self.output_dir}/dev_analytics_dashboard.png")
    
    def export_detailed_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"""
        report_file = f"{self.output_dir}/dev_analytics_report.json"
        
        report_data = {
            'generated_at': datetime.now().isoformat(),
            'analysis_period': '30 days',
            'repositories': self.analysis_data,
            'insights': self.generate_productivity_insights()
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {report_file}")
        
        # ç°¡æ˜“ç‰ˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰
        print("\n" + "="*60)
        print("ğŸš€ takawasié–‹ç™ºåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        insights = self.generate_productivity_insights()
        for insight in insights:
            print(insight)
        
        print("\nğŸ“ˆ è©³ç´°ãƒ‡ãƒ¼ã‚¿:")
        for repo_name, data in self.analysis_data.items():
            print(f"\nğŸ“ {repo_name}:")
            if 'git_activity' in data:
                git_data = data['git_activity']
                print(f"  â€¢ ã‚³ãƒŸãƒƒãƒˆæ•°: {git_data['total_commits']}")
                print(f"  â€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ—¥æ•°: {git_data['active_days']}")
                print(f"  â€¢ è¿½åŠ è¡Œæ•°: {git_data['file_changes']['additions']:,}")
                print(f"  â€¢ å‰Šé™¤è¡Œæ•°: {git_data['file_changes']['deletions']:,}")
            
            if 'code_quality' in data:
                code_data = data['code_quality']
                print(f"  â€¢ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {code_data['total_files']}")
                print(f"  â€¢ ç·è¡Œæ•°: {code_data['total_lines']:,}")
                
                if code_data['languages']:
                    top_lang = max(code_data['languages'].items(), key=lambda x: x[1])
                    print(f"  â€¢ ä¸»è¦è¨€èª: {top_lang[0]} ({top_lang[1]:,} lines)")
    
    def run_analysis(self):
        """åˆ†æå®Ÿè¡Œãƒ¡ã‚¤ãƒ³"""
        print("ğŸš€ takawasié–‹ç™ºåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é–‹å§‹")
        print("="*50)
        
        # Git ãƒªãƒã‚¸ãƒˆãƒªç™ºè¦‹
        repositories = self.discover_git_repositories()
        
        if not repositories:
            print("âŒ Git ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # å„ãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æ
        for repo in repositories:
            print(f"\nğŸ“Š åˆ†æä¸­: {repo['name']}")
            
            # Git æ´»å‹•åˆ†æ
            git_activity = self.analyze_git_activity(repo['path'])
            
            # ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ
            code_quality = self.analyze_code_quality(repo['path'])
            
            self.analysis_data[repo['name']] = {
                'path': repo['path'],
                'git_activity': git_activity,
                'code_quality': code_quality,
                'total_commits': git_activity['total_commits'] if git_activity else 0
            }
            
            if git_activity:
                print(f"  âœ… Gitåˆ†æå®Œäº†: {git_activity['total_commits']} commits")
            if code_quality:
                print(f"  âœ… ã‚³ãƒ¼ãƒ‰åˆ†æå®Œäº†: {code_quality['total_files']} files")
        
        # çµæœå‡ºåŠ›
        self.create_visualizations()
        self.export_detailed_report()
        
        print(f"\nğŸ† åˆ†æå®Œäº†! çµæœã¯ {self.output_dir}/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¯ takawasiå€‹äººé–‹ç™ºåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    print("=" * 50)
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–ãƒ»å®Ÿè¡Œ
    dashboard = DevAnalyticsDashboard()
    dashboard.run_analysis()
    
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("  â€¢ å¯è¦–åŒ–ã‚°ãƒ©ãƒ•: analytics_output/dev_analytics_dashboard.png")
    print("  â€¢ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: analytics_output/dev_analytics_report.json")
    print("  â€¢ å®šæœŸå®Ÿè¡Œæ¨å¥¨: é€±1å›ç¨‹åº¦")
    
    print("\nğŸš€ takawasiå¼é–‹ç™ºåˆ†æå®Œäº†!")
    print("âš¡ é›»æ’ƒæˆ¦æœ€å¼·ï¼ç¾å ´çŒ«å“è³ªç®¡ç†ãƒ¨ã‚·ï¼")


if __name__ == "__main__":
    main()